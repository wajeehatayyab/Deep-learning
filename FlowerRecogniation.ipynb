{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "FlowerRecogniation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wajeehatayyab/Deep-learning/blob/main/FlowerRecogniation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6UrxAWkyIeE"
      },
      "source": [
        "# **Assignment: Flowers Recognition**\n",
        "# **Dataset Description: **\n",
        "\n",
        "This dataset contains 4242 images of flowers.\n",
        "The data collection is based on the data flicr, google images, yandex images.\n",
        "You can use this datastet to recognize plants from the photo.\n",
        "\n",
        "# **Attribute Information: **\n",
        "The pictures are divided into five classes: chamomile, tulip, rose, sunflower, dandelion.\n",
        "For each class there are about 800 photos. Photos are not high resolution, about 320x240 pixels.\n",
        "Also explore how to resize images in tensorflow and then resize all the images to a same size.\n",
        "This is a Multiclass Classification Problem.\n",
        "\n",
        "# **WORKFLOW :**\n",
        "Load Data\n",
        "Split into 60 and 40 ratio.\n",
        "Encode labels.\n",
        "Create Model\n",
        "Compilation Step (Note : Its a Multiclass Classification problem , select loss , metrics according to it)\n",
        "Train the Model.\n",
        "If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .\n",
        "Prediction should be > 85%\n",
        "Evaluation Step\n",
        "Prediction\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# **Data :**\n",
        "https://drive.google.com/file/d/1-OX6wn5gA-bJpjPNfSyaYQLz-A-AB_uj/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHeMvFpkR-Oe"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import RMSprop\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHZNL5dwyHgd",
        "outputId": "94211685-9e29-4a92-b88d-f4cd17744af5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnwvBJUfyvJ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bce3b74-a03f-49fb-99d8-41280d0b2d5f"
      },
      "source": [
        "cd /content/drive/MyDrive/'Deeplearning_Assignment '/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Deeplearning_Assignment \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7IU6vKK9x3b",
        "outputId": "a6f4aafa-bdf7-47e3-ea04-5cd988acba1e"
      },
      "source": [
        "ls"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " CarPrice_Assignment.csv                 CreditCardFraudDetection.ipynb\n",
            " Car_Price_Prediction_assignmenl.ipynb   FlowerRecogniation.ipynb\n",
            " compresive_strength_concrete.csv        \u001b[0m\u001b[01;34mflowers\u001b[0m/\n",
            " ConcreteStrenghtAssignment.ipynb       'Ionosphere Assignment.ipynb'\n",
            " creditcard.csv                          ionosphere_data.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "gu8R1NyOv9Gv",
        "outputId": "f00cec0a-f570-4c1f-d451-b3e914eecede"
      },
      "source": [
        "val_batch = 10\n",
        "train_batch = 32\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        validation_split=0.30,\n",
        "        )\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        './content/drive/MyDrive/Deeplearning_Assignment /flowers/daisy',\n",
        "        target_size=(180, 180),\n",
        "        batch_size=train_batch,\n",
        "        class_mode='sparse',\n",
        "        subset = 'training',\n",
        "        color_mode = 'rgb',\n",
        "        shuffle = True)\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Deeplearning_Assignment /flowers/daisy',\n",
        "        target_size=(180, 180),\n",
        "        batch_size=val_batch,\n",
        "        class_mode='sparse',\n",
        "        subset = 'validation',\n",
        "        color_mode = 'rgb',\n",
        "        shuffle= True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-a3d5572d6f8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0msubset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'training'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcolor_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rgb'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         shuffle = True)\n\u001b[0m\u001b[1;32m     15\u001b[0m validation_generator = train_datagen.flow_from_directory(\n\u001b[1;32m     16\u001b[0m         \u001b[0;34m'/content/drive/MyDrive/Deeplearning_Assignment /flowers/daisy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    956\u001b[0m         \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 958\u001b[0;31m         interpolation=interpolation)\n\u001b[0m\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m   def flow_from_dataframe(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './content/drive/MyDrive/Deeplearning_Assignment /flowers/daisy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RR13ZEf7-zus"
      },
      "source": [
        "train_generator.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqDb5wQt9NSe"
      },
      "source": [
        "type(train_datagen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjjqF1rux_rj"
      },
      "source": [
        "type(train_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0JAwzvh9blZ"
      },
      "source": [
        "train_generator[31][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MECEactbpYY2"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout,Flatten\n",
        "model = Sequential()\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(Dense(8, activation='elu'))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(Dense(5,  activation='softmax))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QFL7tA4D0Sa"
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "loss='sparse_categorical_crossentropy',\n",
        "metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBJbtQp1fhfx"
      },
      "source": [
        "# %tensorflow_version 2.x\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwG7_qctxUBl"
      },
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "    result = model.fit(\n",
        "          train_generator,\n",
        "          steps_per_epoch = 20,\n",
        "          batch_size = train_batch,\n",
        "          validation_data = validation_generator,\n",
        "          validation_batch_size= val_batch,\n",
        "          epochs=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAMVOUBUhcj9"
      },
      "source": [
        "model.evaluate(validation_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ufw4FqsmU-g2"
      },
      "source": [
        "x = result.history.keys()\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOKPsS3HWwUn"
      },
      "source": [
        "\n",
        "# Visualize training history\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "plt.plot(result.history['accuracy'])\n",
        "plt.plot(result.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(result.history['loss'])\n",
        "plt.plot(result.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7p4aMxliqvO"
      },
      "source": [
        "y_pred1 = model.predict(validation_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qhQ6JA_i0YM"
      },
      "source": [
        "y_pred1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRKNoHsBNvdR"
      },
      "source": [
        "list1 = []\n",
        "for i in range(0,len(validation_generator)):\n",
        "    for j in range(0,val_batch):\n",
        "        try:\n",
        "              list1.append(validation_generator[i][1][j].tolist())\n",
        "        except:\n",
        "              break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-SgD9VNRfD-"
      },
      "source": [
        "tf.math.confusion_matrix(\n",
        "    list1, np.argmax(y_pred1, axis=1), num_classes=None, weights=None, dtype=tf.dtypes.int32,\n",
        "    name=None\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}